#### Purpose: Calibrate the logit-normal GAS model with a pool of loans and 1 macro variables

#Time-series
tobs <- unique(DM_1C[DateQtr > 2003]$DateQtr)
#Cross-section
cobs <- matrix(data = 0, nrow = length(tobs), ncol = 1)
  for(i in 1:length(tobs)){
    cobs[i] <- nrow(DM_1C[DateQtr == tobs[i]])
  }
#Macro 
path_n <- matrix(data = 0, nrow = length(tobs), ncol = 1)
for(i in 1:length(tobs)){
  path_n[i] <- unique(DM_1C[DateQtr == tobs[i], get("HPI")])
}
#Default rate
path_l <- matrix(data = 0, nrow = length(tobs), ncol = 1)
for(i in 1:length(tobs)){
  path_l[i] <- sum(DM_1C[DateQtr == tobs[i], Default])/cobs[i]
}


#Likelihood function
loglikelihood <- function(par, path_l, path_n, tobs, cobs){
  f1 <- par[grepl("f1",names(par))]
  Zc <- par[grepl("Zc",names(par))]
  Zm <- par[grepl("Zm",names(par))]
  w <- par[grepl("w",names(par))]
  A <- par[grepl("A",names(par))]
  B <- par[grepl("B",names(par))]
  ssq <- par[grepl("Sigma_squared",names(par))]
  
  #Common
  score_ <- matrix(data = NA, nrow = length(tobs), ncol = 1)
  f_ <- matrix(data = NA, nrow = length(tobs)+1, ncol = 1)
  loglike <- matrix(data = NA, nrow = length(tobs), ncol = 1)
  #Logit
  p_ <- matrix(data = NA, nrow = length(tobs), ncol = 1)
  score_l_ <- matrix(data = NA, nrow = length(tobs), ncol = 1)
  #Normal
  score_n_ <- matrix(data = NA, nrow = length(tobs), ncol = 1)
  
  #Initialize GAS component
  f_[1] <- f1
  
  #compute likelihood and other elements at every t
  for(i in 1:length(tobs)){
    #Dynamic probability for logit component
    p_[i] <- 1/(1 + exp(-Zc*f_[i]))
    
    #Score
    score_l_[i] <- cobs[i]*path_l[i]*Zc - cobs[i]*p_[i]*Zc
    score_n_[i] <- (1/ssq)*Zm*(path_n[i] - Zm*f_[i])
    
    score_[i] <-  score_l_[i] + score_n_[i]
    
    #Log-likelihood
    loglike_l <- cobs[i]*path_l[i]*Zc*f_[i] - cobs[i]*log(1 + exp(Zc*f_[i]))
    loglike_n <- -0.5*log(2*pi*ssq) - 0.5*(1/ssq)*(path_n[i] - Zm*f_[i])^2
    
    loglike[i] <- loglike_n + loglike_l
    
    f_[i+1] <- w + A*score_[i] + B*f_[i]
  }
  
  #compute log-likelihood
  loglike <- sum(loglike)
  return(-loglike)
}


#Initialization
parameters <- c(Zm = 0.5 , Zc = 0.001, B = 0.5, A = 0.5, Sigma_squared = 1, f1 = 0, w = 0)


#Estimation
fit <- optim(par = parameters, fn = loglikelihood, method = "BFGS" , path_l = path_l, 
             path_n = path_n, cobs = cobs, tobs = tobs, control=list(trace = 1, REPORT=1), hessian = TRUE)

#Comparison of fitted default rate with observed default rate:
plot(p_, type = "l")
plot(path_l, type = "l")

#Standard Errors
hi <- solve(-hessian(loglikelihood, par,  path_l = path_l, path_n = path_n, cobs = cobs, tobs = tobs))
se <- sqrt(diag(hi))
#P-values
b <- fit$par
zscore <- b / se
p_value <- 2*(1 - pnorm(abs(zscore)))

#Unconditional mean of Factor
Ef <- fit$par["w"]/(1 - fit$par["B"])

##Conclusions:
#1. The model can appropiately replicate the changes in default rates. 
#   Specially, the generated default rates are much smoother than the ones implied by the subsample DM_1C. Therefore, 
#   more in line with the default rates observed in the complete sample. 
#2. The score is centered around 0 and the factor is centred around its uncond. mean. Therefore, in line with theoretical results. 
#3. The diagonal of the inverse hessian matrix generated by optim( ) cannot be squared due to the negative values. Given the 
#   appropiate results mentioned in 1 and 2, it is assumed the optim( ) function is not providing reliable results for the hessian matrix.

